{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-52 라이브러리 호출\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "torch.manual_seed(125)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-53 데이터 전처리\n",
    "mnist_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-54 데이터셋 내러받기 및 전처리 적용\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "download_root = \"../chap07/MNIST_DATASET\"\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    download_root, transform=mnist_transform, train=True, download=True\n",
    ")\n",
    "valid_dataset = MNIST(\n",
    "    download_root, transform=mnist_transform, train=False, download=True\n",
    ")\n",
    "test_dataset = MNIST(\n",
    "    download_root, transform=mnist_transform, train=False, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-55 데이터셋 메모리로 가져오기\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=True\n",
    ")  # 일반적으로 검증과 테스트 용도의 데이터셋은 섞어서 사용하지 않습니다. 예제에서는 다양한 학습을 위해 True로 지정했습니다.\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-56 변수 값 설정\n",
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-57 GRU 셀 네트워크\n",
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.x2h = nn.Linear(input_size, 3 * hidden_size, bias=bias)  # ①\n",
    "        self.h2h = nn.Linear(hidden_size, 3 * hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):  # 파라미터를 초기화\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.view(-1, x.size(1))\n",
    "\n",
    "        gate_x = self.x2h(\n",
    "            x\n",
    "        )  # LSTM 셀에서는 gates를 x2h+h2h로 정의했지만 GRU 셀에서는 개별적인 상태를 유지합니다.\n",
    "        gate_h = self.h2h(hidden)\n",
    "        gate_x = gate_x.squeeze()\n",
    "        gate_h = gate_h.squeeze()\n",
    "\n",
    "        i_r, i_i, i_n = gate_x.chunk(\n",
    "            3, 1\n",
    "        )  # 총 세 개의 게이트(망각, 입력, 새로운 게이트)를 위해 세 개로 쪼갭니다.\n",
    "        h_r, h_i, h_n = gate_h.chunk(3, 1)\n",
    "\n",
    "        resetgate = F.sigmoid(i_r + h_r)\n",
    "        inputgate = F.sigmoid(i_i + h_i)\n",
    "        newgate = F.tanh(\n",
    "            i_n + (resetgate * h_n)\n",
    "        )  # ‘새로운 게이트’는 탄젠트 활성화 함수가 적용된 게이트\n",
    "\n",
    "        hy = newgate + inputgate * (hidden - newgate)\n",
    "        return hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-58 전반적인 네트워크 구조\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        self.gru_cell = GRUCell(\n",
    "            input_dim, hidden_dim, layer_dim\n",
    "        )  # 앞에서 정의한 GRUCell 함수를 불러옵니다.\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = Variable(\n",
    "                torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()\n",
    "            )\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "\n",
    "        outs = []\n",
    "        hn = h0[\n",
    "            0, :, :\n",
    "        ]  # LSTM 셀에서는 셀 상태에 대해서도 정의했었지만 GRU 셀에서는 셀은 사용되지 않습니다.\n",
    "\n",
    "        for seq in range(x.size(1)):\n",
    "            hn = self.gru_cell(x[:, seq, :], hn)\n",
    "            outs.append(hn)\n",
    "            out = outs[-1].squeeze()\n",
    "            out = self.fc(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-59 옵티마이저와 손실 함수 설정\n",
    "input_dim = 28\n",
    "hidden_dim = 128\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "\n",
    "model = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.3020689487457275. Accuracy: 10.319999694824219\n",
      "Iteration: 1000. Loss: 2.31019926071167. Accuracy: 11.350000381469727\n",
      "Iteration: 1500. Loss: 2.306100845336914. Accuracy: 11.350000381469727\n",
      "Iteration: 2000. Loss: 2.300555944442749. Accuracy: 11.350000381469727\n",
      "Iteration: 2500. Loss: 2.2927582263946533. Accuracy: 11.350000381469727\n",
      "Iteration: 3000. Loss: 2.309049367904663. Accuracy: 11.350000381469727\n",
      "Iteration: 3500. Loss: 2.3057708740234375. Accuracy: 11.350000381469727\n",
      "Iteration: 4000. Loss: 2.304710626602173. Accuracy: 11.350000381469727\n",
      "Iteration: 4500. Loss: 2.307931900024414. Accuracy: 11.350000381469727\n",
      "Iteration: 5000. Loss: 2.2947354316711426. Accuracy: 11.350000381469727\n",
      "Iteration: 5500. Loss: 2.298997640609741. Accuracy: 11.350000381469727\n",
      "Iteration: 6000. Loss: 2.3024721145629883. Accuracy: 11.350000381469727\n",
      "Iteration: 6500. Loss: 2.3102259635925293. Accuracy: 11.350000381469727\n",
      "Iteration: 7000. Loss: 2.3134262561798096. Accuracy: 11.350000381469727\n",
      "Iteration: 7500. Loss: 2.31419038772583. Accuracy: 11.350000381469727\n",
      "Iteration: 8000. Loss: 2.291071653366089. Accuracy: 11.350000381469727\n",
      "Iteration: 8500. Loss: 2.295053005218506. Accuracy: 11.350000381469727\n",
      "Iteration: 9000. Loss: 2.306023120880127. Accuracy: 11.350000381469727\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-60 모델 학습 및 성능 검증\n",
    "seq_dim = 28\n",
    "loss_list = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if torch.cuda.is_available():\n",
    "            loss.cuda()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in valid_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            print(\n",
    "                \"Iteration: {}. Loss: {}. Accuracy: {}\".format(\n",
    "                    iter, loss.item(), accuracy\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-61 테스트 데이터셋을 이용한 모델 예측\n",
    "def evaluate(model, val_iter):\n",
    "    corrects, total, total_loss = 0, 0, 0\n",
    "    model.eval()\n",
    "    for images, labels in val_iter:\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim)).to(device)\n",
    "\n",
    "        logit = model(images).to(device)\n",
    "        labels = labels.to(device)\n",
    "        loss = F.cross_entropy(logit, labels, reduction=\"sum\")\n",
    "        _, predicted = torch.max(logit.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "        corrects += (predicted == labels).sum()\n",
    "\n",
    "    avg_loss = total_loss / len(val_iter.dataset)\n",
    "    avg_accuracy = corrects / total\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  2.30 | Test Accuracy:  0.11\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-62 모델 예측 결과\n",
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
