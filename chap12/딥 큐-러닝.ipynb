{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Using cached gym-0.26.2-py3-none-any.whl\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (from gym) (8.5.0)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (from gym) (1.24.3)\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym) (3.20.2)\n",
      "Installing collected packages: gym-notices, cloudpickle, gym\n",
      "Successfully installed cloudpickle-3.1.0 gym-0.26.2 gym-notices-0.0.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 12-1 라이브러리 호출\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import (\n",
    "    namedtuple,\n",
    ")  # 튜플에 담긴 요소들의 인덱스와 값으로 모두 접근 가능\n",
    "from itertools import count  # 무한 루프 사용을 위한 라이브러리\n",
    "from PIL import Image  # 이미지 처리를 위한 라이브러리\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "env = gym.make(\"CartPole-v1\").unwrapped  # cartpole이라는 강화 학습 환경을 불러옵니다.\n",
    "plt.ion()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 12-2 한글 깨짐 방지\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# font_fname = \"C:/Windows/Fonts/malgun.ttf\"\n",
    "font_fname = \"/mnt/c/Windows/Fonts/malgun.ttf\"\n",
    "font_family = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "plt.rcParams[\"font.family\"] = font_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 12-3 리플레이 메모리\n",
    "Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\"))  # ①\n",
    "\n",
    "\n",
    "class ReplayMemory(object):  # ②\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 12-4 DQN 모델 네트워크\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32  # ①\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(\n",
    "            x.view(x.size(0), -1)\n",
    "        )  # 함수의 반환값은 [[left0exp,right0exp]...]와 같으며 다음 행동을 결정하기 위해 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyglet\n",
      "  Downloading pyglet-2.0.20-py3-none-any.whl (945 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m945.1/945.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyglet\n",
      "Successfully installed pyglet-2.0.20\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# 환경을 초기화\u001b[39;00m\n\u001b[1;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m     45\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mget_screen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy(), interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m )  \u001b[38;5;66;03m# permute 함수는 transpose 함수처럼 차원을 바꾸어서 표현할 때 사용\u001b[39;00m\n\u001b[1;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m화면 예시\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mget_screen\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_screen\u001b[39m():  \u001b[38;5;66;03m# ①\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     screen \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb_array\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# ②\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     _, screen_height, screen_width \u001b[38;5;241m=\u001b[39m screen\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     19\u001b[0m     screen \u001b[38;5;241m=\u001b[39m screen[:, \u001b[38;5;28mint\u001b[39m(screen_height \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.4\u001b[39m) : \u001b[38;5;28mint\u001b[39m(screen_height \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m)]\n",
      "\u001b[0;31mTypeError\u001b[0m: render() got an unexpected keyword argument 'mode'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 코드 12-5 이미지 추출 및 처리\n",
    "import pyglet\n",
    "from PIL import Image\n",
    "\n",
    "resize = T.Compose(\n",
    "    [T.ToPILImage(), T.Resize(40, interpolation=Image.BICUBIC), T.ToTensor()]\n",
    ")  # 이미지 크기 및 텐서 변환\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):  # 카트의 위치 정보 가져오기\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # 카트의 중간(중앙) 위치\n",
    "\n",
    "\n",
    "def get_screen():  # ①\n",
    "    screen = env.render(mode=\"rgb_array\").transpose((2, 0, 1))  # ②\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height * 0.4) : int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "\n",
    "    if (\n",
    "        cart_location < view_width // 2\n",
    "    ):  # 카트는 출력 화면의 아래쪽 중앙에 존재하므로 화면의 위쪽과 아래쪽을 제거\n",
    "        slice_range = slice(view_width)  # ③\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(\n",
    "            cart_location - view_width // 2, cart_location + view_width // 2\n",
    "        )\n",
    "    screen = screen[\n",
    "        :, :, slice_range\n",
    "    ]  # 카트가 화면의 중앙에 위치하도록 가장자리를 제거\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255  # ④\n",
    "    screen = torch.from_numpy(screen)  # 텐서로 변환\n",
    "    return (\n",
    "        resize(screen).unsqueeze(0).to(device)\n",
    "    )  # 출력 크기 조정 및 배치 차원 추가하여 데이터는 (배치, 채널, 높이, 너비)의 형태를 갖습니다.\n",
    "\n",
    "\n",
    "env.reset()  # 환경을 초기화\n",
    "plt.figure()\n",
    "plt.imshow(\n",
    "    get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(), interpolation=\"none\"\n",
    ")  # permute 함수는 transpose 함수처럼 차원을 바꾸어서 표현할 때 사용\n",
    "plt.title(\"화면 예시\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[classic_control] in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (from gym[classic_control]) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (from gym[classic_control]) (3.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (from gym[classic_control]) (8.5.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (from gym[classic_control]) (0.0.8)\n",
      "Collecting pygame==2.1.0\n",
      "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.20 in /home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym[classic_control]) (3.20.2)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym[classic_control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 47732 (\\N{HANGUL SYLLABLE MYEON}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 50696 (\\N{HANGUL SYLLABLE YE}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/halozhan/딥러닝 파이토치 교과서/.venv/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n",
      "findfont: Font family 'Malgun Gothic' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym  # gym 라이브러리 추가\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GPU가 사용 가능하다면, GPU를 사용하도록 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 환경 초기화\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')  # render_mode 설정\n",
    "\n",
    "resize = T.Compose(\n",
    "    [T.ToPILImage(), T.Resize(40, interpolation=Image.BICUBIC), T.ToTensor()]\n",
    ")\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))  # render_mode로 초기화했으므로 인자 필요 없음\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height * 0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(\n",
    "            cart_location - view_width // 2, cart_location + view_width // 2\n",
    "        )\n",
    "    screen = screen[:, :, slice_range]\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(\n",
    "    get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(), interpolation=\"none\"\n",
    ")\n",
    "plt.title(\"화면 예시\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 12-6 모델 객체화 및 손실 함수 정의\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "init_screen = get_screen() # ①\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "n_actions = env.action_space.n # gym에서 행동(action)에 대한 횟수를 가져옵니다.\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict()) # ②\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1) # max(1)은 각 행의 가장 큰 열 값을 반환\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device,  dtype=torch.long)\n",
    "\n",
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 12-7 모델에서 사용할 옵티마이저 정의\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))  # ①\n",
    "    non_final_mask = torch.tensor(\n",
    "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
    "        device=device,\n",
    "        dtype=torch.bool,\n",
    "    )  # ②\n",
    "    non_final_next_states = torch.cat(\n",
    "        [s for s in batch.next_state if s is not None]\n",
    "    )  # torch.cat을 이용하여 s 값들을 이어 붙입니다.\n",
    "\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(\n",
    "        1, action_batch\n",
    "    )  # Q(st,at)를 계산\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = (\n",
    "        target_net(non_final_next_states).max(1)[0].detach()\n",
    "    )  # ③\n",
    "\n",
    "    expected_state_action_values = (\n",
    "        next_state_values * GAMMA\n",
    "    ) + reward_batch  # V(st+1)을 계산\n",
    "\n",
    "    loss = F.smooth_l1_loss(\n",
    "        state_action_values, expected_state_action_values.unsqueeze(1)\n",
    "    )  # ④\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종료\n"
     ]
    }
   ],
   "source": [
    "# 코드 12-8 모델 학습\n",
    "num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()  # 환경과 상태 초기화\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "\n",
    "    for t in count():\n",
    "        action = select_action(state)  # 행동 선택 및 실행\n",
    "        _, reward, done, _, _ = env.step(\n",
    "            action.item()\n",
    "        )  # 선택한 행동(action)을 환경으로 보냅니다.\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "\n",
    "        if not done:  # 새로운 상태 관찰(observe)\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        memory.push(\n",
    "            state, action, next_state, reward\n",
    "        )  # 상태 전이(state transition)를 메모리에 저장\n",
    "        state = next_state  # 다음 상태로 이동\n",
    "\n",
    "        optimize_model()  # 타깃(큐) 네트워크에 대해 최적화 진행\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(\n",
    "            policy_net.state_dict()\n",
    "        )  # 큐 네트워크의 모든 가중치와 바이어스를 복사하여 타깃(큐) 네트워크를 업데이트합니다.\n",
    "\n",
    "print(\"종료\")\n",
    "env.render()  # 화면을 출력\n",
    "env.close()  # 화면을 종료\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
